{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 147)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:147\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "def refreehist_extraction(leagues_list, today_date):\n",
    "    leagues_dataset = {} #Created the empyt dictionary that will be used to concatenate all table from all leagues\n",
    "\n",
    "    for key in list(leagues_list.keys()): #Loops through all the leagues in our list of league url\n",
    "        league_url = leagues_list[key][1]\n",
    "\n",
    "        try:\n",
    "            if league_url == '': \n",
    "                #Checks for empty league links and skips\n",
    "                continue\n",
    "            else:\n",
    "                #Gets the contents from the leagues schedule page\n",
    "                response = requests.get(league_url)\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                #Extracts the table with the match schedules\n",
    "                table = soup.find(\"table\", class_=\"standard_tabelle\")\n",
    "\n",
    "                data = []\n",
    "                match_links = []\n",
    "\n",
    "                #Extracts the table rows\n",
    "                table_rows = table.find_all(\"tr\")\n",
    "                for row in table_rows:\n",
    "                    #Loops through al the rows and extracts the data in each columns\n",
    "                    columns = row.find_all(\"td\")\n",
    "                    row_data = [column.get_text(strip=True) for column in columns]\n",
    "                    data.append(row_data)\n",
    "\n",
    "                    #Extracts the urls of each match\n",
    "                    match_link = row.find(\"a\", href=lambda href: href and \"report\" in href)\n",
    "                    if match_link:\n",
    "                        match_links.append(match_link[\"href\"])\n",
    "                    else:\n",
    "                        match_links.append('')\n",
    "\n",
    "                #Drops the empty entries\n",
    "                zipped_lists = zip(data, match_links)\n",
    "                zipped_lists = [pair for pair in zipped_lists if len(pair[0]) > 0]\n",
    "                data, match_links = zip(*zipped_lists)\n",
    "\n",
    "                columns = ['Date', 'Time', 'Home Team', 'Score', 'Away Team', 'Result', 'Links']\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "                df.Links = match_links\n",
    "\n",
    "                df = df[df['Links'] != ''] #Drops columns with empty url\n",
    "\n",
    "                #Add the prefix to the column\n",
    "                df['Links'] = 'https://www.worldfootball.net' + df['Links']\n",
    "                df['Date'] = df['Date'].replace('', np.nan).ffill()\n",
    "                df['Date'] = pd.to_datetime(df['Date'],  format='%d/%m/%Y')\n",
    "                today = date.today()\n",
    "\n",
    "                #Filter rows with today's date\n",
    "                today_df = df[df['Date'].dt.date == today_date] #Account for when the dataset filter everything due to no matching date\n",
    "                today_df = today_df.copy(deep=True)\n",
    "                curr_league = [key for i in range(len(today_df['Links']))]\n",
    "                today_df['League'] = curr_league\n",
    "\n",
    "                #Extracts the link to the profile of the officiating referee from the match page using match url\n",
    "                referee_urls = []\n",
    "                for match_url in today_df.Links:\n",
    "                    response = requests.get(match_url)\n",
    "                    html_content = response.content\n",
    "                    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "                    referee_links = soup.find_all(\"a\", href=lambda href: href and \"referee_summary\" in href)\n",
    "                    ref_link = []\n",
    "                    if len(referee_links) > 0:\n",
    "                        for link in referee_links:\n",
    "                            link_url = link.get(\"href\")\n",
    "                            ref_link.append(f'https://www.worldfootball.net{link_url}')\n",
    "                            \n",
    "                        ref_link = ref_link[0]\n",
    "                        referee_urls.append(ref_link)\n",
    "                    else:\n",
    "                        referee_urls.append('')\n",
    "\n",
    "                #Add the url of the profile of the officiating referee of each match to dataframe containing daily matches\n",
    "                today_df['Referee_Links'] = referee_urls\n",
    "                #Extracts the url of the most recent matches officiated by the officiating referee\n",
    "                ref_matchhist_url = []\n",
    "                for ref_url in today_df.Referee_Links:\n",
    "                    if ref_url != '':\n",
    "                        ref_matchhist = []\n",
    "\n",
    "                        response = requests.get(ref_url)\n",
    "                        html_content = response.content\n",
    "\n",
    "                        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "                        table = soup.find(\"table\")\n",
    "                        rows = table.find_all(\"tr\")\n",
    "\n",
    "                        for row in rows:\n",
    "                            columns = row.find_all(\"td\")\n",
    "                            for column in columns:\n",
    "                                (column.get_text())\n",
    "\n",
    "                        referee_summary_links = soup.find_all(\"a\", href=lambda href: href and \"referee_summary\" and \"2023-2024\" and \"2022-2023\" in href)\n",
    "\n",
    "                        for link in referee_summary_links:\n",
    "                            link_url = link.get(\"href\")\n",
    "                            ref_matchhist.append(f'https://www.worldfootball.net{link_url}')\n",
    "                        ref_matchhist = [link for link in ref_matchhist if 'referee_summary' in link]\n",
    "\n",
    "                        ref_matchhist_url.append(ref_matchhist)\n",
    "                    else:\n",
    "                        ref_matchhist_url.append([])\n",
    "\n",
    "                #Add the urls of the most recent matches officiated by the referee to the dataframe of daily matches\n",
    "                today_df['Referee_MatchHist_Links'] = ref_matchhist_url\n",
    "\n",
    "                #Extracts the details from each match and stores in a dictionary\n",
    "                ref_matchhist_detail = []\n",
    "                for row in today_df.Referee_MatchHist_Links:\n",
    "                     if row != []:\n",
    "                        data_dict = {'Date':[], 'Home Team':[], 'Away Team':[], 'Score':[], 'Yellow Cards':[], 'Unkown Card':[], 'Red Cards':[]}\n",
    "                        for ref_match_url in row:\n",
    "                            response = requests.get(ref_match_url)\n",
    "                            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "                            table = soup.find(\"table\", class_=\"standard_tabelle\")\n",
    "\n",
    "                            data = [] # List to store table data\n",
    "\n",
    "                            table_rows = table.find_all(\"tr\")\n",
    "                            for row in table_rows:\n",
    "                                columns = row.find_all(\"td\")\n",
    "                                row_data = [column.get_text(strip=True) for column in columns]\n",
    "                                data.append(row_data)\n",
    "\n",
    "                            data = data[1:]\n",
    "                            for entry in data:\n",
    "                                entry.pop(2)\n",
    "\n",
    "                            for entry in data:\n",
    "                                for i in range(len(entry)):\n",
    "                                    keys = list(data_dict.keys())[i]\n",
    "                                    data_dict[keys].append(entry[i])\n",
    "                        ref_matchhist_detail.append(data_dict)\n",
    "                    else:\n",
    "                        ref_matchhist_detail.append({})\n",
    "\n",
    "                #Extracted match details are added to the dataframe of daily matches\n",
    "                today_df['Referee_MatchHist_Details'] = ref_matchhist_detail\n",
    "\n",
    "            leagues_dataset[key] = today_df #Adds the dataframe of daily matches for a league to the dictionary of leagues\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    #All the dataframe of the daily matches for all the leagues extracted are concatenated vertically\n",
    "    list_of_keys = list(leagues_dataset.keys())\n",
    "    if len(list_of_keys) > 0:\n",
    "        for i in range(len(list_of_keys)):\n",
    "            if i == 0:\n",
    "                key = list_of_keys[i]\n",
    "                final_dataset = leagues_dataset[key].copy(deep=True)\n",
    "            else:\n",
    "                key = list_of_keys[i]\n",
    "                final_dataset = pd.concat([final_dataset, leagues_dataset[key]], axis=0)\n",
    "\n",
    "        return final_dataset\n",
    "    else:\n",
    "        print('No league scheduled matches were extracted!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'refreehist_extraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m testleagues_list \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m#'English Premier League':['https://www.flashscore.nl/voetbal/engeland/premier-league/schema/', 'https://www.worldfootball.net/all_matches/eng-premier-league-2023-2024/'],\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m#'EFL Championship':['https://www.flashscore.nl/voetbal/engeland/efl-cup/schema/', ''],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSerie B\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m'\u001b[39m\u001b[39mhttps://www.flashscore.nl/voetbal/italie/serie-b/schema/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps://www.worldfootball.net/all_matches/ita-serie-b-2023-2024/\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m referee_dataset \u001b[39m=\u001b[39m refreehist_extraction(testleagues_list, tomorrow)\n\u001b[1;32m     10\u001b[0m referee_dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'refreehist_extraction' is not defined"
     ]
    }
   ],
   "source": [
    "testleagues_list = {\n",
    "    #'English Premier League':['https://www.flashscore.nl/voetbal/engeland/premier-league/schema/', 'https://www.worldfootball.net/all_matches/eng-premier-league-2023-2024/'],\n",
    "    #'EFL Championship':['https://www.flashscore.nl/voetbal/engeland/efl-cup/schema/', ''],\n",
    "    #'EFL Trophy':['https://www.flashscore.nl/voetbal/engeland/efl-trophy/schema/', 'https://www.worldfootball.net/all_matches/eng-efl-trophy-2023-2024/'],\n",
    "    #'La Liga':['https://www.flashscore.nl/voetbal/spanje/laliga/schema/','https://www.worldfootball.net/all_matches/esp-primera-division-2023-2024/'],\n",
    "    #'La Liga2':['https://www.flashscore.nl/voetbal/spanje/laliga2/schema/', 'https://www.worldfootball.net/all_matches/esp-segunda-division-2023-2024/']\n",
    "    'Serie B':['https://www.flashscore.nl/voetbal/italie/serie-b/schema/', 'https://www.worldfootball.net/all_matches/ita-serie-b-2023-2024/'],\n",
    "}\n",
    "referee_dataset = refreehist_extraction(testleagues_list, tomorrow)\n",
    "referee_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referee link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "/referees/eng-premier-league-2022-2023/1/\n",
      "/referee_summary/michael-salisbury/3/1/eng-premier-league-2022-2023/\n",
      "/referees/eng-championship-2022-2023/1/\n",
      "/referee_summary/michael-salisbury/3/1/eng-championship-2022-2023/\n",
      "/referees/eng-fa-cup-2022-2023/1/\n",
      "/referee_summary/michael-salisbury/3/1/eng-fa-cup-2022-2023/\n",
      "/referees/eng-league-cup-2022-2023/1/\n",
      "/referee_summary/michael-salisbury/3/1/eng-league-cup-2022-2023/\n",
      "/referees/eng-playoffs-2022-2023-league-one/1/\n",
      "/referee_summary/michael-salisbury/3/1/eng-playoffs-2022-2023-league-one/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.worldfootball.net//referee_summary/michael-salisbury/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\")\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    for column in columns:\n",
    "        (column.get_text())\n",
    "\n",
    "\n",
    "print(\"=\" * 50) \n",
    "referee_summary_links = soup.find_all(\"a\", href=lambda href: href and \"referee_summary\" and \"2023-2024\" and \"2022-2023\" in href)\n",
    "\n",
    "# Extract and print the href attributes of the links\n",
    "for link in referee_summary_links:\n",
    "    link_url = link.get(\"href\")\n",
    "    print(link_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refereed link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['04/10/2022', 'Cardiff City', '-', 'Blackburn Rovers', '1:0', '4', '-', '-'],\n",
       " ['01/11/2022', 'Luton Town', '-', 'Reading FC', '0:0', '5', '-', '-'],\n",
       " ['26/12/2022', 'Hull City', '-', 'Blackpool FC', '1:1', '4', '-', '1'],\n",
       " ['25/02/2023', 'Reading FC', '-', 'Blackpool FC', '3:1', '1', '-', '-']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.worldfootball.net/referee_summary/john-brooks_2/3/1/eng-championship-2022-2023/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"standard_tabelle\")\n",
    "\n",
    "data = []  # List to store table data\n",
    "\n",
    "table_rows = table.find_all(\"tr\")\n",
    "for row in table_rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    row_data = [column.get_text(strip=True) for column in columns]\n",
    "    data.append(row_data)\n",
    "\n",
    "data = data[1:]\n",
    "\n",
    "columns = ['Date', 'Home Team', 'Score', 'Away Team', 'Result', 'Links']\n",
    "df = pd.DataFrame(data, columns=columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
